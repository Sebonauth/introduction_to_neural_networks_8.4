<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>An Example of Forward Propagation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #ffffff;
            font-size: 150%;
        }
        section {
            margin-bottom: 20px;
            padding: 20px;
            background-color: #ffffff;
            display: none;
            opacity: 0;
            transition: opacity 0.5s ease-in;
        }
        p {
            line-height: 1.6;
            color: #444;
            margin-bottom: 20px;
        }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            margin: 20px 0;
        }
        .continue-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #007bff;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .continue-button:hover {
            background-color: #0056b3;
        }
        .frequently-asked {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
            color: #333;
        }
        .frequently-asked h4 {
            margin-bottom: 10px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <section id="section1">
        <p>Let's work through a simple example of forward propagation in a small network.</p>
        <div class="continue-button" data-next-section="2">Continue</div>
    </section>

    <section id="section2">
        <p>Consider a network with 2 inputs, one hidden layer with 2 neurons, and one output neuron.</p>
        <img src="path-to-network-diagram.jpg" alt="A small neural network with 2 inputs, 2 hidden neurons, and 1 output neuron, showing weights and biases labeled.">
        <div class="continue-button" data-next-section="3">Continue</div>
    </section>

    <section id="section3">
        <p>Suppose the input vector is:</p>
        <p>\[ \mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} \]</p>
        <div class="continue-button" data-next-section="4">Continue</div>
    </section>

    <section id="section4">
        <p>Weights for the hidden layer neurons are:</p>
        <p>\[ \mathbf{W}^{[1]} = \begin{bmatrix} w_{11}^{[1]} & w_{12}^{[1]} \\ w_{21}^{[1]} & w_{22}^{[1]} \end{bmatrix} = \begin{bmatrix} 0.5 & -0.6 \\ -0.3 & 0.8 \end{bmatrix} \]</p>
        <div class="continue-button" data-next-section="5">Continue</div>
    </section>

    <section id="section5">
        <p>Biases for the hidden layer are:</p>
        <p>\[ \mathbf{b}^{[1]} = \begin{bmatrix} b_1^{[1]} \\ b_2^{[1]} \end{bmatrix} = \begin{bmatrix} 0.1 \\ -0.1 \end{bmatrix} \]</p>
        <div class="continue-button" data-next-section="6">Continue</div>
    </section>

    <section id="section6">
        <p>Weights and bias for the output neuron are:</p>
        <p>\[ \mathbf{w}^{[2]} = \begin{bmatrix} w_1^{[2]} & w_2^{[2]} \end{bmatrix} = \begin{bmatrix} 0.7 & -0.5 \end{bmatrix} \]</p>
        <p>\[ b^{[2]} = 0.2 \]</p>
        <div class="continue-button" data-next-section="7">Continue</div>
    </section>

    <section id="section7">
        <p>First, compute the weighted sums for the hidden layer:</p>
        <p>\[ \mathbf{z}^{[1]} = \mathbf{W}^{[1]} \mathbf{x} + \mathbf{b}^{[1]} \]</p>
        <div class="continue-button" data-next-section="8">Continue</div>
    </section>

    <section id="section8">
        <p>Calculating \( \mathbf{z}^{[1]} \):</p>
        <p>\[ \mathbf{z}^{[1]} = \begin{bmatrix} 0.5 & -0.6 \\ -0.3 & 0.8 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} + \begin{bmatrix} 0.1 \\ -0.1 \end{bmatrix} = \begin{bmatrix} 0.6 \\ -0.4 \end{bmatrix} \]</p>
        <div class="continue-button" data-next-section="9">Continue</div>
    </section>

    <section id="section9">
        <p>Next, apply the activation function (let's use ReLU) to get \( \mathbf{a}^{[1]} \):</p>
        <p>\[ \mathbf{a}^{[1]} = \text{ReLU}(\mathbf{z}^{[1]}) = \begin{bmatrix} \max(0, 0.6) \\ \max(0, -0.4) \end{bmatrix} = \begin{bmatrix} 0.6 \\ 0 \end{bmatrix} \]</p>
        <div class="continue-button" data-next-section="10">Continue</div>
    </section>

    <section id="section10">
        <p>Now, compute the weighted sum for the output neuron:</p>
        <p>\[ z^{[2]} = \mathbf{w}^{[2]} \cdot \mathbf{a}^{[1]} + b^{[2]} = 0.62 \]</p>
        <div class="continue-button" data-next-section="11">Continue</div>
    </section>

    <section id="section11">
        <p>Finally, apply the activation function to \( z^{[2]} \) to get the output \( a^{[2]} \). Let's use a sigmoid function here:</p>
        <p>\[ a^{[2]} = \sigma(z^{[2]}) = \frac{1}{1 + e^{-0.62}} \approx 0.650 \]</p>
        <div class="continue-button" data-next-section="12">Continue</div>
    </section>

    <section id="section12">
        <p>So, the final output of the network is approximately 0.650.</p>
        <div class="frequently-asked">
            <h4>Frequently Asked Question</h4>
            <p><strong>Q:</strong> Why do we use different activation functions in different layers?</p>
            <p><strong>A:</strong> Different activation functions serve different purposes. ReLU is often used in hidden layers because it helps mitigate the vanishing gradient problem and accelerates convergence. Sigmoid or softmax functions are commonly used in output layers for binary classification or probability outputs.</p>
        </div>
    </section>

    <script>
        document.getElementById("section1").style.display = "block";
        document.getElementById("section1").style.opacity = "1";

        document.addEventListener('click', (event) => {
            if (event.target.classList.contains('continue-button')) {
                const nextSectionId = event.target.getAttribute('data-next-section');
                const nextSection = document.getElementById(`section${nextSectionId}`);
                event.target.style.display = "none";
                nextSection.style.display = "block";
                setTimeout(() => nextSection.style.opacity = "1", 10);
                setTimeout(() => nextSection.scrollIntoView({ behavior: 'smooth' }), 500);
            }
        });
    </script>
</body>
</html>
